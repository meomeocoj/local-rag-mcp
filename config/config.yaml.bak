chunking:
  strategy: "headers"  # Using LangChain MarkdownHeaderTextSplitter
  max_chunk_size: 2048  # Optimal for header-based chunking
  overlap: 100  # Character overlap for context continuity

embedding:
  provider: "openai"  # "openai" "sentence_transformers"
  model: "Qwen3-8B-AWQ"
  endpoint: "http://210.211.99.160:8282/v1"
  api_key: "dummy"  # Required by OpenAI client but unused
  batch_size: 32  # Maximum batch size for Qwen3 endpoint

vector_store:
  type: "chromadb"
  persist_directory: "./data/chroma_db"
  collection_name: "documents"
  distance_metric: "cosine"

retrieval:
  type: "hybrid"  # "dense" (vector only), "sparse" (BM25 only), or "hybrid" (combined)
  alpha: 0.5  # Weight for dense vs sparse (0=sparse only, 1=dense only, 0.5=balanced)
  bm25_k1: 1.5  # BM25 term frequency saturation parameter
  bm25_b: 0.75  # BM25 length normalization parameter
  initial_k: 20  # Retrieve more candidates before reranking
  final_k: 10  # Final number of results after combination

generation:
  provider: "openai"  # LiteLLM supports: openai, anthropic, cohere, etc.
  model: "gpt-3.5-turbo"
  temperature: 0.7
  max_tokens: 512
  top_k: 10  # Number of chunks to retrieve (~10k tokens total for agent)
